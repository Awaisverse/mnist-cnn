{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Your Trained MNIST CNN Model\n",
        "\n",
        "This notebook loads and tests your trained model locally.\n",
        "\n",
        "Run all cells to test your model on the MNIST test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('src')\n",
        "from model import MNISTCNN\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üñ•Ô∏è  GPU DETECTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(f\"‚úÖ GPU FOUND! Using: {device}\")\n",
        "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    print(\"\\nüöÄ Testing will run on GPU - Fast inference expected!\")\n",
        "    USE_GPU = True\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Using: CPU\")\n",
        "    print(\"   Testing will run on CPU (slower but still works)\")\n",
        "    USE_GPU = False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = 'models/mnist_cnn_model.pth'\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"‚ùå Model not found at {model_path}\")\n",
        "    print(\"\\nüìù Make sure you've downloaded the model from Kaggle!\")\n",
        "    print(\"   Place it in: models/mnist_cnn_model.pth\")\n",
        "else:\n",
        "    print(f\"‚úÖ Model file found at: {model_path}\")\n",
        "    model = MNISTCNN()\n",
        "    \n",
        "    if USE_GPU:\n",
        "        model.load_state_dict(torch.load(model_path, map_location='cuda'))\n",
        "        model = model.to(device)\n",
        "        print(f\"‚úÖ Model loaded on GPU: {device}\")\n",
        "    else:\n",
        "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
        "        print(\"‚úÖ Model loaded on CPU\")\n",
        "    \n",
        "    model.eval()\n",
        "    print(\"‚úÖ Model ready for inference!\")\n",
        "    \n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"üìä Model parameters: {total_params:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "test_dataset = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Test dataset loaded: {len(test_dataset)} samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test on Random Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model, image_tensor, device):\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image_tensor.unsqueeze(0))\n",
        "        probabilities = F.softmax(output, dim=1)\n",
        "        predicted = torch.argmax(output, dim=1)\n",
        "        confidence = probabilities[0][predicted].item() * 100\n",
        "    return predicted.item(), confidence\n",
        "\n",
        "num_samples = 10\n",
        "indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
        "\n",
        "print(f\"Testing on {num_samples} random samples:\")\n",
        "if USE_GPU:\n",
        "    print(f\"üöÄ Using GPU: {device}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  Using CPU\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "correct = 0\n",
        "for i, idx in enumerate(indices):\n",
        "    image, true_label = test_dataset[idx]\n",
        "    predicted, confidence = predict(model, image, device)\n",
        "    is_correct = predicted == true_label\n",
        "    if is_correct:\n",
        "        correct += 1\n",
        "    \n",
        "    status = \"‚úì\" if is_correct else \"‚úó\"\n",
        "    print(f\"Sample {i+1}: True={true_label}, Predicted={predicted}, \"\n",
        "          f\"Confidence={confidence:.2f}%, {status}\")\n",
        "\n",
        "accuracy = 100 * correct / num_samples\n",
        "print(\"=\" * 60)\n",
        "print(f\"Accuracy on {num_samples} samples: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "fig.suptitle('Model Predictions on Test Samples', fontsize=14)\n",
        "\n",
        "for i, idx in enumerate(indices):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    ax = axes[row, col]\n",
        "    \n",
        "    image, true_label = test_dataset[idx]\n",
        "    predicted, confidence = predict(model, image, device)\n",
        "    \n",
        "    image_display = image.squeeze().cpu().numpy()\n",
        "    ax.imshow(image_display, cmap='gray')\n",
        "    \n",
        "    color = 'green' if predicted == true_label else 'red'\n",
        "    ax.set_title(f'True: {true_label}\\nPred: {predicted} ({confidence:.1f}%)', \n",
        "                 color=color, fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Calculate Overall Test Accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(\"Calculating accuracy on full test set...\")\n",
        "if USE_GPU:\n",
        "    print(f\"üöÄ Using GPU: {device} - Fast inference expected!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Using CPU - This may take a minute...\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "accuracy = 100 * correct / total\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"Overall Test Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Correct: {correct}/{total}\")\n",
        "print(f\"Time taken: {elapsed_time:.2f} seconds\")\n",
        "if USE_GPU:\n",
        "    print(f\"üöÄ GPU acceleration active!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
